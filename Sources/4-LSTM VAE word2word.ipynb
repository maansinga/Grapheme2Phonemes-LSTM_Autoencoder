{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    words = []\n",
    "    with open(\"words.txt\") as fi:\n",
    "        line = fi.readline()\n",
    "        while(len(line)!=0):\n",
    "            datapoint = line.split(' ')\n",
    "            phon = datapoint[1].split('.')\n",
    "            phon[-1] = phon[-1][:-1]\n",
    "            words.append([datapoint[0], phon])\n",
    "            line = fi.readline()\n",
    "            \n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['aback', ['AH', 'B', 'AE', 'K']],\n",
       " ['abandon', ['AH', 'B', 'AE', 'N', 'D', 'AH', 'N']],\n",
       " ['abandoned', ['AH', 'B', 'AE', 'N', 'D', 'AH', 'N', 'D']],\n",
       " ['abandoning', ['AH', 'B', 'AE', 'N', 'D', 'AH', 'N', 'IH', 'NG']],\n",
       " ['abandons', ['AH', 'B', 'AE', 'N', 'D', 'AH', 'N', 'Z']]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xraw = [k[0] for  k in data]\n",
    "Yraw = [k[1] for  k in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aback', 'abandon', 'abandoned', 'abandoning', 'abandons']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xraw[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 22468, 'uncharacteristically')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xrawlens = np.array([len(x) for x in Xraw])\n",
    "Xrawlens.max(), Xrawlens.argmax(), Xraw[Xrawlens.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['AH', 'B', 'AE', 'K'],\n",
       " ['AH', 'B', 'AE', 'N', 'D', 'AH', 'N'],\n",
       " ['AH', 'B', 'AE', 'N', 'D', 'AH', 'N', 'D'],\n",
       " ['AH', 'B', 'AE', 'N', 'D', 'AH', 'N', 'IH', 'NG'],\n",
       " ['AH', 'B', 'AE', 'N', 'D', 'AH', 'N', 'Z']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yraw[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,\n",
       " 4046,\n",
       " ['K',\n",
       "  'AA',\n",
       "  'M',\n",
       "  'P',\n",
       "  'AA',\n",
       "  'R',\n",
       "  'T',\n",
       "  'M',\n",
       "  'EH',\n",
       "  'N',\n",
       "  'T',\n",
       "  'AH',\n",
       "  'L',\n",
       "  'AY',\n",
       "  'Z',\n",
       "  'D'],\n",
       " 'compartmentalized')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yrawlens = np.array([len(y) for y in Yraw])\n",
    "Yrawlens.max(), Yrawlens.argmax(), Yraw[Yrawlens.argmax()], Xraw[Yrawlens.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2tensor(word, wordmaxlen=24):\n",
    "    word2tensor.dummy_char_vec = np.array([0]*26)\n",
    "    wordvec_array = []\n",
    "\n",
    "    for eachcharacter in word:\n",
    "        tempchar = word2tensor.dummy_char_vec.copy()\n",
    "        tempchar[ord(eachcharacter) - ord('a')] = 1\n",
    "        wordvec_array.append(tempchar)\n",
    "        \n",
    "    return np.array(wordvec_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def word2tensor(word, wordmaxlen=24):\n",
    "#     # print(word)\n",
    "#     word = '`' + word + '{'\n",
    "#     wordvec_array = []\n",
    "#     padding = wordmaxlen - len(word)\n",
    "#     for eachcharacter in word:\n",
    "#         tempchar = (ord(eachcharacter) - ord('`'))/27.0\n",
    "#         wordvec_array.append(tempchar)\n",
    "        \n",
    "#     for i in range(padding):\n",
    "#         wordvec_array.append((ord('{') - ord('`'))/27.0)\n",
    "#     return np.array(wordvec_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = word2tensor(\"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]]), (4, 26))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting words to tensor representations and save them for fast loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24167,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = np.array([word2tensor(w) for w in Xraw])\n",
    "words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_shape = words.shape\n",
    "np.savez_compressed('words2vec.npz', words = words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.load('words2vec.npz')\n",
    "# words = data['words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phonemes: There are 39 phonemes, as shown below:\n",
    "`\n",
    "AA     odd     AA D        |   AE      at      AE T      \n",
    "AH      hut     HH AH T     |   AO      ought   AO T     \n",
    "AW      cow     K AW        |   AY      hide    HH AY D  \n",
    "B       be      B IY        |   CH      cheese  CH IY Z  \n",
    "D       dee     D IY        |   DH      thee    DH IY    \n",
    "EH      Ed      EH D        |   ER      hurt    HH ER T  \n",
    "EY      ate     EY T        |   F       fee     F IY     \n",
    "G       green   G R IY N    |   HH      he      HH IY    \n",
    "IH      it      IH T        |   IY      eat     IY T     \n",
    "JH      gee     JH IY       |   K       key     K IY     \n",
    "L       lee     L IY        |   M       me      M IY     \n",
    "N       knee    N IY        |   NG      ping    P IH NG  \n",
    "OW      oat     OW T        |   OY      toy     T OY     \n",
    "P       pee     P IY        |   R       read    R IY D   \n",
    "S       sea     S IY        |   SH      she     SH IY    \n",
    "T       tea     T IY        |   TH      theta   TH EY T AH \n",
    "UH      hood    HH UH D     |   UW      two     T UW     \n",
    "V       vee     V IY        |   W       we      W IY     \n",
    "Y       yield   Y IY L D    |   Z       zee     Z IY     \n",
    "ZH      seizure S IY ZH ER  | \n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_array = [\n",
    "    'AA',\n",
    "    'AE',\n",
    "    'AH',\n",
    "    'AO',\n",
    "    'AW',\n",
    "    'AY',\n",
    "    'B',\n",
    "    'CH',\n",
    "    'D',\n",
    "    'DH',\n",
    "    'EH',\n",
    "    'ER',\n",
    "    'EY',\n",
    "    'F',\n",
    "    'G',\n",
    "    'HH',\n",
    "    'IH',\n",
    "    'IY',\n",
    "    'JH',\n",
    "    'K',\n",
    "    'L',\n",
    "    'M',\n",
    "    'N',\n",
    "    'NG',\n",
    "    'OW',\n",
    "    'OY',\n",
    "    'P',\n",
    "    'R',\n",
    "    'S',\n",
    "    'SH',\n",
    "    'T',\n",
    "    'TH',\n",
    "    'UH',\n",
    "    'UW',\n",
    "    'V',\n",
    "    'W',\n",
    "    'Y',\n",
    "    'Z',\n",
    "    'ZH'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA': 0,\n",
       " 'AE': 1,\n",
       " 'AH': 2,\n",
       " 'AO': 3,\n",
       " 'AW': 4,\n",
       " 'AY': 5,\n",
       " 'B': 6,\n",
       " 'CH': 7,\n",
       " 'D': 8,\n",
       " 'DH': 9,\n",
       " 'EH': 10,\n",
       " 'ER': 11,\n",
       " 'EY': 12,\n",
       " 'F': 13,\n",
       " 'G': 14,\n",
       " 'HH': 15,\n",
       " 'IH': 16,\n",
       " 'IY': 17,\n",
       " 'JH': 18,\n",
       " 'K': 19,\n",
       " 'L': 20,\n",
       " 'M': 21,\n",
       " 'N': 22,\n",
       " 'NG': 23,\n",
       " 'OW': 24,\n",
       " 'OY': 25,\n",
       " 'P': 26,\n",
       " 'R': 27,\n",
       " 'S': 28,\n",
       " 'SH': 29,\n",
       " 'T': 30,\n",
       " 'TH': 31,\n",
       " 'UH': 32,\n",
       " 'UW': 33,\n",
       " 'V': 34,\n",
       " 'W': 35,\n",
       " 'Y': 36,\n",
       " 'Z': 37,\n",
       " 'ZH': 38}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneme_map = dict(zip(phoneme_array, range(len(phoneme_array))))\n",
    "phoneme_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phonemes2tensor(phonemes, phonemesmaxlen=20):\n",
    "    phonemes2tensor.dummy_phoneme_vec = np.array([0]*39) # dummy phonetic symbol as stop\n",
    "    phonemesvec_array = []\n",
    "\n",
    "    for eachphoneme in phonemes:\n",
    "        tempphoneme = phonemes2tensor.dummy_phoneme_vec.copy()\n",
    "        tempphoneme[phoneme_map[eachphoneme]] = 1\n",
    "        phonemesvec_array.append(tempphoneme)\n",
    "        \n",
    "    return np.array(phonemesvec_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def phonemes2tensor(phonemes, phonemesmaxlen=20):\n",
    "#     # print(word)\n",
    "#     phonemes = ['\\s'] + phonemes + ['\\e']\n",
    "#     phonemesvec_array = []\n",
    "#     padding = phonemesmaxlen - len(phonemes)\n",
    "#     for eachphoneme in phonemes:\n",
    "#         tempphoneme = phoneme_map[eachphoneme]\n",
    "#         phonemesvec_array.append(tempphoneme/40.0)\n",
    "        \n",
    "#     for i in range(padding):\n",
    "#         phonemesvec_array.append(1.0)\n",
    "#     return np.array(phonemesvec_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " (9, 39),\n",
       " ['AH', 'B', 'R', 'IY', 'V', 'IY', 'EY', 'T', 'S'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = phonemes2tensor(Yraw[12])\n",
    "result, result.shape, Yraw[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24167,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonemes = np.array([phonemes2tensor(p) for p in Yraw])\n",
    "phonemes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_shape = words.shape\n",
    "np.savez_compressed('phonemes2vec.npz', phonemes = words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.load('words2vec.npz')\n",
    "# phonemes = data['phonemes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "- Create a 2 stacked lstm.\n",
    "- Keep feeding one-hot character vectors until the word is exhausted\n",
    "- Take the final hypothesis of this lstm and feed it to a Dense layer : This should be my internal representation\n",
    "\n",
    "- Loss measure1: Dense layer to convert internal-rep to character count\n",
    "- Loss measure2: Dense layer to convert internal-rep to phoneme count - parameter for next\n",
    "- Loss measure3: Dense layer to convert internal-rep to phonemes output\n",
    "\n",
    "- Loss = rms of loss1, loss2, loss3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train = [2*i+1 for i in range(int(len(words)/2))]\n",
    "indices_test = [2*i for i in range(int(len(words)/2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = words[indices_train]\n",
    "train_phonemes = phonemes[indices_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = words[indices_test]\n",
    "test_phonemes = phonemes[indices_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('train_words.npz', train_words=train_words)\n",
    "np.savez_compressed('train_phonemes.npz', train_phonemes=train_phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('test_words.npz', test_words=test_words)\n",
    "np.savez_compressed('test_phonemes.npz', test_phonemes=test_phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.Input(shape=(26,1), batch_size=1, name=\"input\", dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm1 = tf.keras.layers.LSTM(64, return_sequences=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = lstm1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "_d1 = tf.keras.layers.Dense(64, activation='relu')(H)\n",
    "d1 = tf.keras.layers.Dense(1, activation='relu')(_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "_d2 = tf.keras.layers.Dense(64, activation='relu')(H)\n",
    "d2 = tf.keras.layers.Dense(1, activation='relu')(_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losses(y_pred, y):\n",
    "    return tf.add((y_pred - y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#------------ Lets train LSTM to predict word lenth and phoneme lengths properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = [tw.shape[0] for tw in train_words]\n",
    "pl = [ph.shape[0] for ph in train_phonemes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([list(k) for k in zip(wl, pl)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  7],\n",
       "       [10,  9],\n",
       "       [ 5,  4],\n",
       "       ...,\n",
       "       [ 6,  5],\n",
       "       [ 4,  3],\n",
       "       [ 7,  5]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, LSTM, RepeatVector\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras import objectives\n",
    "\n",
    "\n",
    "def create_lstm_vae(input_dim, \n",
    "    timesteps, \n",
    "    batch_size, \n",
    "    intermediate_dim, \n",
    "    latent_dim,\n",
    "    epsilon_std=1.):\n",
    "\n",
    "    \"\"\"\n",
    "    Creates an LSTM Variational Autoencoder (VAE). Returns VAE, Encoder, Generator. \n",
    "\n",
    "    # Arguments\n",
    "        input_dim: int.\n",
    "        timesteps: int, input timestep dimension.\n",
    "        batch_size: int.\n",
    "        intermediate_dim: int, output shape of LSTM. \n",
    "        latent_dim: int, latent z-layer shape. \n",
    "        epsilon_std: float, z-layer sigma.\n",
    "\n",
    "\n",
    "    # References\n",
    "        - [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)\n",
    "        - [Generating sentences from a continuous space](https://arxiv.org/abs/1511.06349)\n",
    "    \"\"\"\n",
    "    x = Input(shape=(timesteps, input_dim,))\n",
    "\n",
    "    # LSTM encoding\n",
    "    h = LSTM(intermediate_dim)(x)\n",
    "\n",
    "    # VAE Z layer\n",
    "    z_mean = Dense(latent_dim)(h)\n",
    "    z_log_sigma = Dense(latent_dim)(h)\n",
    "    \n",
    "    def sampling(args):\n",
    "        z_mean, z_log_sigma = args\n",
    "        epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
    "                                  mean=0., stddev=epsilon_std)\n",
    "        return z_mean + z_log_sigma * epsilon\n",
    "\n",
    "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "    # so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])\n",
    "    \n",
    "    # decoded LSTM layer\n",
    "    decoder_h = LSTM(intermediate_dim, return_sequences=True)\n",
    "    decoder_mean = LSTM(input_dim, return_sequences=True)\n",
    "\n",
    "    h_decoded = RepeatVector(timesteps)(z)\n",
    "    h_decoded = decoder_h(h_decoded)\n",
    "\n",
    "    # decoded layer\n",
    "    x_decoded_mean = decoder_mean(h_decoded)\n",
    "    \n",
    "    # end-to-end autoencoder\n",
    "    vae = Model(x, x_decoded_mean)\n",
    "\n",
    "    # encoder, from inputs to latent space\n",
    "    encoder = Model(x, z_mean)\n",
    "\n",
    "    # generator, from latent space to reconstructed inputs\n",
    "    decoder_input = Input(shape=(latent_dim,))\n",
    "\n",
    "    _h_decoded = RepeatVector(timesteps)(decoder_input)\n",
    "    _h_decoded = decoder_h(_h_decoded)\n",
    "\n",
    "    _x_decoded_mean = decoder_mean(_h_decoded)\n",
    "    generator = Model(decoder_input, _x_decoded_mean)\n",
    "    \n",
    "    def vae_loss(x, x_decoded_mean):\n",
    "        xent_loss = objectives.mse(x, x_decoded_mean)\n",
    "        kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma))\n",
    "        loss = xent_loss + kl_loss\n",
    "        return loss\n",
    "\n",
    "    vae.compile(optimizer='rmsprop', loss=vae_loss)\n",
    "    \n",
    "    return vae, encoder, generator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae, enc, gen = create_lstm_vae(26, \n",
    "    timesteps=1, \n",
    "    batch_size=1, \n",
    "    intermediate_dim=32,\n",
    "    latent_dim=100,\n",
    "epsilon_std=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_7 to have 3 dimensions, but got array with shape (7, 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-72d311d15d9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_phonemes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    953\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    956\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    124\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    127\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_7 to have 3 dimensions, but got array with shape (7, 26)"
     ]
    }
   ],
   "source": [
    "for i in range(train_words.shape[0]):\n",
    "    vae.fit(x=train_words[i], y=train_phonemes[i], epochs=2, batch_size=train_words[i].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
