{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "from nltk.corpus import wordnet as wn\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    words = []\n",
    "    with open(\"words.txt\") as fi:\n",
    "        line = fi.readline()\n",
    "        while(len(line)!=0):\n",
    "            datapoint = line.split(' ')\n",
    "            phon = datapoint[1].split('.')\n",
    "            phon[-1] = phon[-1][:-1]\n",
    "            words.append([datapoint[0], phon])\n",
    "            line = fi.readline()\n",
    "            \n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['aback', ['AH', 'B', 'AE', 'K']],\n",
       " ['abandon', ['AH', 'B', 'AE', 'N', 'D', 'AH', 'N']],\n",
       " ['abandoned', ['AH', 'B', 'AE', 'N', 'D', 'AH', 'N', 'D']],\n",
       " ['abandoning', ['AH', 'B', 'AE', 'N', 'D', 'AH', 'N', 'IH', 'NG']],\n",
       " ['abandons', ['AH', 'B', 'AE', 'N', 'D', 'AH', 'N', 'Z']],\n",
       " ['abash', ['AH', 'B', 'AE', 'SH']],\n",
       " ['abashed', ['AH', 'B', 'AE', 'SH', 'T']],\n",
       " ['abate', ['AH', 'B', 'EY', 'T']],\n",
       " ['abated', ['AH', 'B', 'EY', 'T', 'IH', 'D']],\n",
       " ['abates', ['AH', 'B', 'EY', 'T', 'S']],\n",
       " ['abating', ['AH', 'B', 'EY', 'T', 'IH', 'NG']],\n",
       " ['abbreviate', ['AH', 'B', 'R', 'IY', 'V', 'IY', 'EY', 'T']],\n",
       " ['abbreviates', ['AH', 'B', 'R', 'IY', 'V', 'IY', 'EY', 'T', 'S']],\n",
       " ['abbreviating', ['AH', 'B', 'R', 'IY', 'V', 'IY', 'EY', 'T', 'IH', 'NG']],\n",
       " ['abdicate', ['AE', 'B', 'D', 'AH', 'K', 'EY', 'T']],\n",
       " ['abdicated', ['AE', 'B', 'D', 'AH', 'K', 'EY', 'T', 'AH', 'D']],\n",
       " ['abdicates', ['AE', 'B', 'D', 'AH', 'K', 'EY', 'T', 'S']],\n",
       " ['abdicating', ['AE', 'B', 'D', 'IH', 'K', 'EY', 'T', 'IH', 'NG']],\n",
       " ['abduct', ['AE', 'B', 'D', 'AH', 'K', 'T']],\n",
       " ['abducts', ['AE', 'B', 'D', 'AH', 'K', 'T', 'S']]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([_x[0] for _x in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([_y[1] for _y in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlen = np.array([len(_x) for _x in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The largest word is*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22468"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(xlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unchartered'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[22470]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[list([0, 1, 0, 2, 10, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26]),\n",
       "        list([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
       "       [list([0, 1, 0, 13, 3, 14, 13, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26]),\n",
       "        list([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
       "       [list([0, 1, 0, 13, 3, 14, 13, 4, 3, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26]),\n",
       "        list([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
       "       ...,\n",
       "       [list([25, 14, 14, 12, 4, 3, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26]),\n",
       "        list([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
       "       [list([25, 14, 14, 12, 8, 13, 6, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26]),\n",
       "        list([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
       "       [list([25, 14, 14, 12, 18, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26]),\n",
       "        list([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "\n",
    "for eachword in x:\n",
    "    reword = [ord(c)-ord('a') for c in list(eachword)]\n",
    "    \n",
    "    vword = reword + [ord('z')-ord('a')+1]*(24-len(reword))\n",
    "    vmask = [1]*len(reword) + [0]*(24-len(reword))\n",
    "    X.append(np.array([vword, vmask]).T)\n",
    "    \n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 48334 into shape (24167,26,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-cd04c0e1bd5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m24167\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m26\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 48334 into shape (24167,26,1)"
     ]
    }
   ],
   "source": [
    "X.reshape((24167, 26, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24167, 24, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of this approach is that, a word is a fixed size vector of 24 rows and 2 columns. The first column is the word represented in character ordinates. The padding for the fixed size is filled with a new character with ord = 26. This represents no-characters/word termination.\n",
    "\n",
    "The other column is the mask that tells which rows of the word vector are valid characters of the word and which are padding. 1 - character from word / 0 - padding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following approach is to run CNN and generate an autoencoder that can regenerate words with highest accuracy with minimal representation. The logic is that, this current representation is extremely sparse. But if we can auto encode it into a single vector that upon decoding regenerates the word as it is.\n",
    "\n",
    "Once this is fully functional, we can plug the encoder part into another CNN to learn the number of phonemes based on the word. This will be the first step towards phonetics prediction.  Using the encoded representation and predicted phonetic representation size, we can build an LSTM that can generate the actual phonetic representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Major flaw in this approach is that - the idea of using numeric representation for characters imply scale invariance. That is, 'aback' is as legitimate as 'bcbdl' based on cosine similarity.\n",
    "\n",
    "+ The complete on-hot representation would be way too sparse for a CNN to work with and generate some reasonable internal representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This trial is expected to fail. But an attempt is always worth it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'units'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-049667d77a17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# at this point the representation is (4, 4, 8) i.e. 128-dimensional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GPU:1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUpSampling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'units'"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "with tf.device('GPU:0'):\n",
    "    input_img = Input(shape=(24, 2, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "    x = Conv2D(64, (, 1), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((1, 1), padding='same')(x)\n",
    "    x = Conv2D(64, (1, 1), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((1, 1), padding='same')(x)\n",
    "    x = Conv2D(64, (1, 1), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((1, 1), padding='same')(x)\n",
    "    x = Conv2D(64, (1, 1), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((1, 1), padding='same')(x)\n",
    "    \n",
    "    \n",
    "    encoded = MaxPooling2D((1, 1), padding='same')(x)\n",
    "\n",
    "    # at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "with tf.device('GPU:1'):\n",
    "    x = Dense()\n",
    "    x = Conv2D(16, (3, 2), activation='relu', padding='same')(encoded)\n",
    "    x = UpSampling2D((1, 1))(x)\n",
    "    x = Conv2D(32, (2, 2), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((1, 1))(x)\n",
    "    x = Conv2D(64, (1, 2), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((1, 1))(x)\n",
    "    decoded = Conv2D(1, (3, 2), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    autoencoder.summary()\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24169 samples, validate on 24169 samples\n",
      "Epoch 1/100\n",
      "24169/24169 [==============================] - 19s 778us/step - loss: 233.8290 - val_loss: 233.7365\n",
      "Epoch 2/100\n",
      "24169/24169 [==============================] - 18s 746us/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 3/100\n",
      "24169/24169 [==============================] - 18s 762us/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 4/100\n",
      "24169/24169 [==============================] - 18s 756us/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 5/100\n",
      "24169/24169 [==============================] - 19s 789us/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 6/100\n",
      "24169/24169 [==============================] - 18s 758us/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 7/100\n",
      "24169/24169 [==============================] - 18s 738us/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 8/100\n",
      "24169/24169 [==============================] - 19s 797us/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 9/100\n",
      "24169/24169 [==============================] - 20s 817us/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 10/100\n",
      "24169/24169 [==============================] - 30s 1ms/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 11/100\n",
      "24169/24169 [==============================] - 33s 1ms/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 12/100\n",
      "24169/24169 [==============================] - 28s 1ms/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 13/100\n",
      "24169/24169 [==============================] - 31s 1ms/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 14/100\n",
      "24169/24169 [==============================] - 27s 1ms/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 15/100\n",
      "24169/24169 [==============================] - 26s 1ms/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 16/100\n",
      "24169/24169 [==============================] - 25s 1ms/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 17/100\n",
      "24169/24169 [==============================] - 26s 1ms/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 18/100\n",
      "24169/24169 [==============================] - 26s 1ms/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 19/100\n",
      "24169/24169 [==============================] - 27s 1ms/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 20/100\n",
      "24169/24169 [==============================] - 27s 1ms/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 21/100\n",
      "24169/24169 [==============================] - 27s 1ms/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 22/100\n",
      "24169/24169 [==============================] - 27s 1ms/step - loss: 233.7365 - val_loss: 233.7365\n",
      "Epoch 23/100\n",
      "12688/24169 [==============>...............] - ETA: 9s - loss: 233.5526"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-5558be350a71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                     callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n\u001b[0m",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device('GPU:1'):\n",
    "    autoencoder.fit(X, X,\n",
    "                    epochs=100,\n",
    "                    batch_size=16,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X, X),\n",
    "                    callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
